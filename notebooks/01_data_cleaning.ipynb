{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4511ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/full_text.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d7b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter One\n",
      "\n",
      "Arrest--Conversation with Mrs. Grubach--Then Miss Bürstner\n",
      "\n",
      "\n",
      "Someone must have been telling lies about Josef K., he knew he had done\n",
      "nothing wrong but, one morning, he was arrested. Every day at eight in\n",
      "the morning he was brought his breakfast by Mrs. Grubach's cook--Mrs.\n",
      "Grubach was his landlady--but today she didn't come. That had never\n",
      "happened before. K. waited a little while, looked from his pillow at the\n",
      "old woman who lived opposite and who was watching him with an\n",
      "inquisitiveness quite unusual for her, and finally, both hungry and\n",
      "disconcerted, rang the bell. There was immediately a knock at the door\n",
      "and a man entered. He had never seen the man in this house before. He\n",
      "was slim but firmly built, his clothes were black and close-fitting,\n",
      "with many folds and pockets, buckles and buttons and a belt, all of\n",
      "which gave the impression of being very practical but without making it\n",
      "very clear what they were actually for. \"Who are you?\" asked K., sitting\n",
      "half upright in his\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520dafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 10\n",
      "First chapter content:\n",
      "Arrest--Conversation with Mrs. Grubach--Then Miss Bürstner\n",
      "\n",
      "\n",
      "Someone must have been telling lies about Josef K., he knew he had done\n",
      "nothing wrong but, one morning, he was arrested. Every day at eight in\n",
      "the morning he was brought his breakfast by Mrs. Grubach's cook--Mrs.\n",
      "Grubach was his landlady--but today she didn't come. That had never\n",
      "happened before. K. waited a little while, looked from his pillow at the\n",
      "old woman who lived opposite and who was watching him with an\n",
      "inquisitiveness quite u\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split on \"Chapter\" followed by word characters\n",
    "chapters = re.split(r'\\bChapter\\s+[A-Za-z]+\\b', text)\n",
    "\n",
    "# First element before Chapter One will be empty/introduction → remove it\n",
    "chapters = [ch.strip() for ch in chapters if ch.strip()]\n",
    "\n",
    "# Print the first chapter to verify\n",
    "print(\"Number of chapters:\", len(chapters))\n",
    "print(\"First chapter content:\")\n",
    "print(chapters[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cd676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drawn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drawn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in first chapter after cleaning: 35265\n",
      "First 100 words in first chapter after cleaning: ['arrest', 'conversation', 'grubach', 'miss', 'bürstner', 'someone', 'must', 'telling', 'lies', 'josef', 'knew', 'done', 'nothing', 'wrong', 'one', 'morning', 'arrested', 'every', 'day', 'eight', 'morning', 'brought', 'breakfast', 'grubach', 'cook', 'grubach', 'landlady', 'today', 'come', 'never', 'happened', 'waited', 'little', 'looked', 'pillow', 'old', 'woman', 'lived', 'opposite', 'watching', 'inquisitiveness', 'quite', 'unusual', 'finally', 'hungry', 'disconcerted', 'rang', 'bell', 'immediately', 'knock', 'door', 'man', 'entered', 'never', 'seen', 'man', 'house', 'slim', 'firmly', 'built', 'clothes', 'black', 'many', 'folds', 'pockets', 'buckles', 'buttons', 'belt', 'gave', 'impression', 'practical', 'without', 'making', 'clear', 'actually', 'asked', 'sitting', 'half', 'upright', 'bed', 'man', 'however', 'ignored', 'question', 'arrival', 'simply', 'accepted', 'merely', 'replied', 'rang', 'anna', 'brought', 'breakfast', 'said', 'tried', 'work', 'man', 'actually', 'first', 'silence']\n",
      "Total number of words across all chapters after cleaning: 35265\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# clean first chapter\n",
    "words = word_tokenize(chapters[0].lower())\n",
    "filtered_words = [w for w in words if w.isalpha() and w not in stop_words]\n",
    "\n",
    "#clean all chapters\n",
    "filtered_words = []\n",
    "for i in range(0, len(chapters)):\n",
    "    words = word_tokenize(chapters[i].lower())\n",
    "    filtered_words.extend([w for w in words if w.isalpha() and w not in stop_words]) #this will keep all words that are alphabetic and not in stop words\n",
    "\n",
    "length_of_filtered_words = len(filtered_words)\n",
    "print(\"Number of words in first chapter after cleaning:\", len(filtered_words))\n",
    "print(\"First 100 words in first chapter after cleaning:\", filtered_words[:100])\n",
    "print(\"Total number of words across all chapters after cleaning:\", length_of_filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1ef4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file for each chapter\n",
    "import os       \n",
    "output_dir = \"../data/cleaned_chapters\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for i, chapter in enumerate(chapters):\n",
    "    chapter_file_path = os.path.join(output_dir, f\"chapter_{i+1}_nostopwords.txt\")\n",
    "    with open(chapter_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(chapter.strip())        \n",
    "# one file for all chapters\n",
    "all_chapters_file_path = os.path.join(output_dir, \"all_chapters_nostopwords.txt\")\n",
    "with open(all_chapters_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(chapters).strip())  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
